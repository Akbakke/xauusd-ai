#!/usr/bin/env python3
"""
Aggregator for MULTIYEAR OVERLAP PROFILE validation results.

Generates:
- Per-profile multiyear reports (MULTIYEAR_PROFILE_REPORT_<profile>.md)
- Per-profile metrics (MULTIYEAR_PROFILE_METRICS_<profile>.json)
- Comparison report (MULTIYEAR_OVERLAP_PROFILE_COMPARISON_2020_2025.md)
"""

import argparse
import json
import logging
from pathlib import Path
from typing import Any, Dict, List, Optional

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
log = logging.getLogger(__name__)


def load_year_metrics(profile_dir: Path, year: int) -> Optional[Dict[str, Any]]:
    """Load metrics for a specific year-profile."""
    year_dir = profile_dir / f"YEAR_{year}"
    
    # BUGFIX: ALWAYS use FULLYEAR_TRIAL160_METRICS_*.json (aggregated) as truth
    # This is generated by generate_year_report() in run_trial160_year_job.py
    metrics_files = list(year_dir.glob("FULLYEAR_TRIAL160_METRICS_*.json"))
    
    if not metrics_files:
        log.warning(f"[{profile_dir.name} {year}] FULLYEAR_TRIAL160_METRICS_*.json not found, trying fallbacks...")
        # Fallback: try merged metrics from orchestrator
        merged_metrics = list(year_dir.glob("metrics_*_MERGED.json"))
        if merged_metrics:
            metrics_files = merged_metrics
            log.warning(f"[{profile_dir.name} {year}] Using merged metrics (not ideal)")
    
    if not metrics_files:
        # Last resort: chunk_0 metrics (for minimal output mode)
        chunk_0_dir = year_dir / "chunk_0"
        if chunk_0_dir.exists():
            chunk_metrics = list(chunk_0_dir.glob("metrics_*.json"))
            if chunk_metrics:
                metrics_files = chunk_metrics
                log.warning(f"[{profile_dir.name} {year}] Using chunk_0 metrics (not ideal - should use aggregated)")
    
    if not metrics_files:
        return None
    
    with open(metrics_files[0], "r") as f:
        metrics = json.load(f)
        # BUGFIX: Add metrics_source to metadata
        if "FULLYEAR_TRIAL160_METRICS" in metrics_files[0].name:
            metrics["_metrics_source"] = "aggregated"
        elif "MERGED" in metrics_files[0].name:
            metrics["_metrics_source"] = "merged"
        else:
            metrics["_metrics_source"] = "chunk_0"
        return metrics


def aggregate_profile(
    profile_id: str,
    profile_dir: Path,
    years: List[int],
) -> Dict[str, Any]:
    """Aggregate metrics for a single profile across all years."""
    log.info(f"Aggregating {profile_id}...")
    
    profile_metrics = {
        "profile_id": profile_id,
        "years": {},
        "multiyear": {
            "total_pnl_bps": 0.0,
            "total_trades": 0,
            "worst_maxdd": 0.0,
            "worst_year": None,
            "best_year": None,
            "best_year_pnl": None,
        },
    }
    
    year_pnls = []
    for year in years:
        year_metrics = load_year_metrics(profile_dir, year)
        if year_metrics is None:
            log.warning(f"[{profile_id}] Year {year} metrics not found")
            continue
        
        year_pnl = year_metrics.get("total_pnl_bps", 0.0)
        year_maxdd = abs(year_metrics.get("max_dd", year_metrics.get("max_drawdown_bps", 0.0)))
        year_trades = year_metrics.get("n_trades", 0)
        
        # BUGFIX: Extract per-session metrics
        session_breakdown = year_metrics.get("session_breakdown", {})
        session_metrics = {}
        for session in ["ASIA", "EU", "OVERLAP", "US"]:
            session_data = session_breakdown.get(session, {})
            session_metrics[session] = {
                "pnl_bps": session_data.get("total_pnl_bps", 0.0),
                "trades": session_data.get("n_trades", 0),
                "maxdd": abs(session_data.get("max_dd", 0.0)),
            }
        
        profile_metrics["years"][year] = {
            "total_pnl_bps": year_pnl,
            "total_trades": year_trades,
            "maxdd": year_maxdd,
            "session_breakdown": session_metrics,
        }
        
        profile_metrics["multiyear"]["total_pnl_bps"] += year_pnl
        profile_metrics["multiyear"]["total_trades"] += year_trades
        
        if year_maxdd > abs(profile_metrics["multiyear"]["worst_maxdd"]):
            profile_metrics["multiyear"]["worst_maxdd"] = -year_maxdd
            profile_metrics["multiyear"]["worst_year"] = year
        
        year_pnls.append((year, year_pnl))
    
    if year_pnls:
        best_year, best_pnl = max(year_pnls, key=lambda x: x[1])
        profile_metrics["multiyear"]["best_year"] = best_year
        profile_metrics["multiyear"]["best_year_pnl"] = best_pnl
    
    return profile_metrics


def generate_profile_report(
    profile_metrics: Dict[str, Any],
    output_path: Path,
) -> None:
    """Generate markdown report for a single profile."""
    profile_id = profile_metrics["profile_id"]
    multiyear = profile_metrics["multiyear"]
    
    with open(output_path, "w") as f:
        f.write(f"# MULTIYEAR PROFILE REPORT: {profile_id}\n\n")
        f.write(f"Generated: {Path(__file__).stat().st_mtime}\n\n")
        
        f.write("## Executive Summary\n\n")
        f.write(f"- **Total PnL (2020-2025)**: {multiyear['total_pnl_bps']:.2f} bps\n")
        f.write(f"- **Total Trades**: {multiyear['total_trades']:,}\n")
        f.write(f"- **Worst MaxDD**: {multiyear['worst_maxdd']:.2f} bps (Year: {multiyear['worst_year']})\n")
        f.write(f"- **Best Year**: {multiyear['best_year']} ({multiyear['best_year_pnl']:.2f} bps)\n\n")
        
        f.write("## Per-Year Breakdown\n\n")
        f.write("| Year | PnL (bps) | Trades | MaxDD (bps) | OVERLAP PnL | OVERLAP Trades |\n")
        f.write("|------|-----------|--------|-------------|-------------|----------------|\n")
        
        for year in sorted(profile_metrics["years"].keys()):
            year_data = profile_metrics["years"][year]
            overlap_data = year_data.get("session_breakdown", {}).get("OVERLAP", {})
            f.write(
                f"| {year} | {year_data['total_pnl_bps']:.2f} | "
                f"{year_data['total_trades']:,} | {year_data['maxdd']:.2f} | "
                f"{overlap_data.get('pnl_bps', 0.0):.2f} | {overlap_data.get('trades', 0):,} |\n"
            )
    
    log.info(f"✅ Profile report written: {output_path}")


def generate_comparison_report(
    all_profiles: List[Dict[str, Any]],
    baseline_profile: Optional[Dict[str, Any]],
    output_path: Path,
) -> None:
    """Generate comparison report across all profiles."""
    with open(output_path, "w") as f:
        f.write("# MULTIYEAR OVERLAP PROFILE COMPARISON (2020-2025)\n\n")
        f.write(f"Generated: {Path(__file__).stat().st_mtime}\n\n")
        
        f.write("## Summary Table\n\n")
        f.write("| Profile ID | Total PnL (bps) | Worst Year PnL | MaxDD Worst Year | Total Trades |\n")
        f.write("|------------|-----------------|----------------|------------------|--------------|\n")
        
        for profile in all_profiles:
            profile_id = profile["profile_id"]
            multiyear = profile["multiyear"]
            worst_year = multiyear.get("worst_year")
            worst_year_pnl = profile["years"].get(worst_year, {}).get("total_pnl_bps", 0.0) if worst_year else 0.0
            
            f.write(
                f"| {profile_id} | {multiyear['total_pnl_bps']:.2f} | "
                f"{worst_year_pnl:.2f} | {multiyear['worst_maxdd']:.2f} | "
                f"{multiyear['total_trades']:,} |\n"
            )
        
        if baseline_profile:
            f.write("\n## Delta vs Baseline\n\n")
            baseline_multiyear = baseline_profile["multiyear"]
            f.write("| Profile ID | PnL Δ (bps) | MaxDD Δ (bps) | Trades Δ | OVERLAP PnL Δ | OVERLAP Trades Δ |\n")
            f.write("|------------|-------------|---------------|----------|---------------|------------------|\n")
            
            # Calculate baseline OVERLAP metrics
            baseline_overlap_pnl = 0.0
            baseline_overlap_trades = 0
            for year in sorted(baseline_profile["years"].keys()):
                year_data = baseline_profile["years"][year]
                overlap_data = year_data.get("session_breakdown", {}).get("OVERLAP", {})
                baseline_overlap_pnl += overlap_data.get("pnl_bps", 0.0)
                baseline_overlap_trades += overlap_data.get("trades", 0)
            
            for profile in all_profiles:
                if profile["profile_id"] == "BASELINE":
                    continue
                
                profile_id = profile["profile_id"]
                multiyear = profile["multiyear"]
                
                pnl_delta = multiyear["total_pnl_bps"] - baseline_multiyear["total_pnl_bps"]
                maxdd_delta = multiyear["worst_maxdd"] - baseline_multiyear["worst_maxdd"]
                trades_delta = multiyear["total_trades"] - baseline_multiyear["total_trades"]
                
                # Calculate OVERLAP delta
                profile_overlap_pnl = 0.0
                profile_overlap_trades = 0
                for year in sorted(profile["years"].keys()):
                    year_data = profile["years"][year]
                    overlap_data = year_data.get("session_breakdown", {}).get("OVERLAP", {})
                    profile_overlap_pnl += overlap_data.get("pnl_bps", 0.0)
                    profile_overlap_trades += overlap_data.get("trades", 0)
                
                overlap_pnl_delta = profile_overlap_pnl - baseline_overlap_pnl
                overlap_trades_delta = profile_overlap_trades - baseline_overlap_trades
                
                f.write(
                    f"| {profile_id} | {pnl_delta:+.2f} | "
                    f"{maxdd_delta:+.2f} | {trades_delta:+,} | "
                    f"{overlap_pnl_delta:+.2f} | {overlap_trades_delta:+,} |\n"
                )
    
    log.info(f"✅ Comparison report written: {output_path}")


def aggregate_all_profiles(out_root: Path, years: List[int]) -> None:
    """Aggregate all profiles in out_root. Can be called programmatically."""
    output_root = out_root.resolve()
    
    # Find all profile directories (dynamically, not hardcoded)
    profile_ids = ["BASELINE", "OVERLAP_COST_STRICT", "OVERLAP_WINDOW_TIGHT"]
    all_profiles = []
    baseline_profile = None
    
    for profile_id in profile_ids:
        profile_dir = output_root / profile_id
        if not profile_dir.exists():
            log.warning(f"Profile directory not found: {profile_dir}")
            continue
        
        profile_metrics = aggregate_profile(profile_id, profile_dir, years)
        all_profiles.append(profile_metrics)
        
        if profile_id == "BASELINE":
            baseline_profile = profile_metrics
        
        # Generate per-profile report
        report_path = output_root / f"MULTIYEAR_PROFILE_REPORT_{profile_id}.md"
        generate_profile_report(profile_metrics, report_path)
        
        # Generate per-profile metrics JSON
        metrics_path = output_root / f"MULTIYEAR_PROFILE_METRICS_{profile_id}.json"
        with open(metrics_path, "w") as f:
            json.dump(profile_metrics, f, indent=2)
        log.info(f"✅ Profile metrics written: {metrics_path}")
    
    # Generate comparison report
    comparison_path = output_root / "MULTIYEAR_OVERLAP_PROFILE_COMPARISON_2020_2025.md"
    generate_comparison_report(all_profiles, baseline_profile, comparison_path)
    
    log.info("=" * 80)
    log.info("✅ Aggregation complete")
    log.info("=" * 80)


def main():
    parser = argparse.ArgumentParser(
        description="Aggregate MULTIYEAR OVERLAP PROFILE validation results"
    )
    parser.add_argument("--out-root", type=Path, required=True, help="Root output directory")
    parser.add_argument("--years", type=str, default="2020,2021,2022,2023,2024,2025", help="Comma-separated years")
    
    args = parser.parse_args()
    
    years = [int(y.strip()) for y in args.years.split(",")]
    aggregate_all_profiles(args.out_root, years)


if __name__ == "__main__":
    main()
